{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c842ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned DataFrame loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utilities import get_data_path\n",
    "\n",
    "# Use the same file name as earlier\n",
    "file_name = \"2025_presidential_round2.csv\"\n",
    "cleaned_path = get_data_path(\"processed\", \"poland\", f\"{file_name[:-4]}_clean.csv\")\n",
    "\n",
    "# Load the cleaned DataFrame\n",
    "df = pd.read_csv(cleaned_path, sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Cleaned DataFrame loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43188efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)  # or specify a number instead of None, e.g., 100\n",
    "# pd.set_option('display.max_rows', 100)          # Control max rows shown\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a375ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty postal codes\n",
    "df = df[df[\"postal_code\"].notna()]\n",
    "\n",
    "# and possible zagranica:\n",
    "df = df[df[\"teryt_gmina\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1753cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define bucket sizes\n",
    "MIN_BUCKET_SIZE = 10\n",
    "MAX_BUCKET_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43b5d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean postal codes: remove dash\n",
    "df['postal_clean'] = df['postal_code'].str.replace('-', '')\n",
    "df['postal_clean_value_count'] = df['postal_clean'].map(df['postal_clean'].value_counts())\n",
    "\n",
    "df['postal_2'] = df['postal_clean'].astype(str).str[:2]\n",
    "df['postal_3'] = df['postal_clean'].astype(str).str[:3]\n",
    "df['postal_3_value_count'] = df['postal_3'].map(df['postal_3'].value_counts())\n",
    "df['postal_4'] = df['postal_clean'].astype(str).str[:4]\n",
    "df['postal_4_value_count'] = df['postal_4'].map(df['postal_4'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf17d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get value counts\n",
    "postal_3_counts = df['postal_3'].value_counts()\n",
    "\n",
    "# Step 2: Find postal_3 values with count between 10 and 16\n",
    "valid_postals = postal_3_counts[(postal_3_counts >= MIN_BUCKET_SIZE) & (postal_3_counts <= MAX_BUCKET_SIZE)].index\n",
    "\n",
    "# Step 3: Assign 'bucket' column based on valid_postals\n",
    "df['bucket'] = df['postal_3'].where(df['postal_3'].isin(valid_postals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8645c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.bucket.notna()].head(100)\n",
    "# df[df.bucket == \"513\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8f00b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_4_counts = df['postal_4'].value_counts()\n",
    "valid_postals_4 = postal_4_counts[\n",
    "    (postal_4_counts >= MIN_BUCKET_SIZE ) & (postal_4_counts <= MAX_BUCKET_SIZE )\n",
    "].index\n",
    "\n",
    "df.loc[df['bucket'].isna(), 'bucket'] = df.loc[\n",
    "    df['postal_4'].isin(valid_postals_4), 'postal_4'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc4cec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "# df[df.bucket.notna()]\n",
    "# df[df.bucket==\"5973\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c1f2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Extract 4-digit prefix from postal_clean\n",
    "df['postal_4'] = df['postal_clean'].str[:4]\n",
    "\n",
    "# Step 5: Work only on rows where bucket is still null and 3-digit group was too big\n",
    "mask_postal_4 = df['bucket'].isna() & (df['postal_3_value_count'] > MAX_BUCKET_SIZE)\n",
    "\n",
    "# Step 6: Get value counts for postal_4 within that mask\n",
    "postal_4_counts = df.loc[mask_postal_4, 'postal_4'].value_counts()\n",
    "\n",
    "# Step 7: Find postal_4 values with count between 10 and 16\n",
    "valid_postal_4s = postal_4_counts[(postal_4_counts >= MIN_BUCKET_SIZE) & (postal_4_counts <= MAX_BUCKET_SIZE)].index\n",
    "\n",
    "# Step 8: Assign bucket for valid postal_4s (only where bucket is still null)\n",
    "df.loc[mask_postal_4, 'bucket'] = df.loc[mask_postal_4, 'postal_4'].where(\n",
    "    df.loc[mask_postal_4, 'postal_4'].isin(valid_postal_4s)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73112cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.bucket.notna()]\n",
    "# df[df.bucket == \"5973\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2d7a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Bucket remaining by postal_clean (postal_5) if count >= 10\n",
    "postal_clean_counts = df['postal_clean'].value_counts()\n",
    "valid_postal_5 = postal_clean_counts[postal_clean_counts >= MIN_BUCKET_SIZE].index\n",
    "\n",
    "mask = df['bucket'].isna() & df['postal_clean'].isin(valid_postal_5)\n",
    "df.loc[mask, 'bucket'] = df.loc[mask, 'postal_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c876c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.bucket.head(100)\n",
    "# df[df.bucket == \"58260\"]\n",
    "\n",
    "# df[df.postal_4 == \"5826\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1e0847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Get 5-digit prefix (full postal code, already cleaned)\n",
    "df['postal_5'] = df['postal_clean']  # optional, for clarity\n",
    "\n",
    "# Step 10: Build mask for rows to consider\n",
    "mask_postal_5 = (\n",
    "    df['bucket'].isna() &\n",
    "    (\n",
    "        (df['postal_3_value_count'] > MAX_BUCKET_SIZE) |\n",
    "        (df['postal_4'].map(df['postal_4'].value_counts()) > MAX_BUCKET_SIZE)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 11: Count postal_5 frequencies only within this mask\n",
    "postal_5_counts = df.loc[mask_postal_5, 'postal_5'].value_counts()\n",
    "\n",
    "# Step 12: Find valid postal_5 codes where count is between 10 and 16\n",
    "valid_postal_5s = postal_5_counts[(postal_5_counts >= MIN_BUCKET_SIZE) & (postal_5_counts <= MAX_BUCKET_SIZE)].index\n",
    "\n",
    "# Step 13: Assign those postal_5s to bucket\n",
    "df.loc[mask_postal_5, 'bucket'] = df.loc[mask_postal_5, 'postal_5'].where(\n",
    "    df.loc[mask_postal_5, 'postal_5'].isin(valid_postal_5s)\n",
    ")\n",
    "\n",
    "# Step 14: Preserve oversized groups that share the exact same 5-digit code (don’t split)\n",
    "for postal_code, count in postal_5_counts.items():\n",
    "    if count > MAX_BUCKET_SIZE:\n",
    "        # Check if all rows with this code are still ungrouped\n",
    "        same_postal_mask = (df['postal_5'] == postal_code) & df['bucket'].isna()\n",
    "        if same_postal_mask.sum() == count:\n",
    "            df.loc[same_postal_mask, 'bucket'] = postal_code  # assign full postal_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8705d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df.bucket.isna()].count()\n",
    "# df.bucket.value_counts()\n",
    "# x = df.bucket.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd08ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 15: Get all remaining unassigned polling stations\n",
    "leftovers = df[df['bucket'].isna()].copy()\n",
    "\n",
    "# Container for merged leftover groups\n",
    "new_buckets = []\n",
    "\n",
    "# Step 16: Group leftovers by postal_3\n",
    "for prefix, group in leftovers.groupby('postal_3'):\n",
    "    # Sort by full postal code to ensure continuity\n",
    "    group_sorted = group.sort_values(by='postal_clean')\n",
    "    \n",
    "    # Chunk into groups of 10–16\n",
    "    i = 0\n",
    "    while i < len(group_sorted):\n",
    "        chunk = group_sorted.iloc[i:i+16]\n",
    "        if len(chunk) >= 10:\n",
    "            bucket_id = f\"{prefix}_L{i//16}\"\n",
    "            df.loc[chunk.index, 'bucket'] = bucket_id\n",
    "            i += len(chunk)\n",
    "        else:\n",
    "            break  # remaining rows too small to form a valid group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b85d4b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.bucket.isna()].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cc76b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17: Get final leftovers (still no bucket)\n",
    "final_leftovers = df[df['bucket'].isna()].copy()\n",
    "\n",
    "# Group existing bucket sizes for each postal_3 to try merging into them\n",
    "existing_buckets = df.dropna(subset=['bucket']).copy()\n",
    "existing_buckets['bucket_size'] = existing_buckets.groupby('bucket')['bucket'].transform('count')\n",
    "\n",
    "# Try to merge final leftovers into nearby groups\n",
    "for prefix, group in final_leftovers.groupby('postal_3'):\n",
    "    group_sorted = group.sort_values(by='postal_clean')\n",
    "    existing_in_prefix = existing_buckets[\n",
    "        existing_buckets['postal_3'] == prefix\n",
    "    ].groupby('bucket').first()\n",
    "\n",
    "    assigned = False\n",
    "    for idx, row in group_sorted.iterrows():\n",
    "        # Try to append to a not-too-large existing group\n",
    "        for bucket_id, b_row in existing_in_prefix.iterrows():\n",
    "            current_size = df[df['bucket'] == bucket_id].shape[0]\n",
    "            if current_size < MAX_BUCKET_SIZE:\n",
    "                df.at[idx, 'bucket'] = bucket_id\n",
    "                assigned = True\n",
    "                break\n",
    "\n",
    "        # If no spot found, assign a new fallback bucket anyway\n",
    "        if pd.isna(df.at[idx, 'bucket']):\n",
    "            fallback_id = f\"{prefix}_F{idx}\"\n",
    "            df.at[idx, 'bucket'] = fallback_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7a09285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3015"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bucket.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10a7e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets with 10–16 items: 1462 (48.5%)\n",
      "Buckets with 6–30 items:  1719 (57.0%)\n"
     ]
    }
   ],
   "source": [
    "# Get value counts per bucket\n",
    "bucket_sizes = df['bucket'].value_counts()\n",
    "\n",
    "# Count how many buckets fall into each range\n",
    "buckets_10_16 = bucket_sizes[(bucket_sizes >= 10) & (bucket_sizes <= 16)].count()\n",
    "buckets_6_30  = bucket_sizes[(bucket_sizes >= 6) & (bucket_sizes <= 30)].count()\n",
    "\n",
    "# Optional: total number of buckets\n",
    "total_buckets = bucket_sizes.count()\n",
    "\n",
    "# Display results\n",
    "print(f\"Buckets with 10–16 items: {buckets_10_16} ({buckets_10_16 / total_buckets:.1%})\")\n",
    "print(f\"Buckets with 6–30 items:  {buckets_6_30} ({buckets_6_30 / total_buckets:.1%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01973ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
